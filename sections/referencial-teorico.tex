\section{Referencial Teórico}\label{sec:referencial-teorico}

Nesta Seção, os principais conceitos relacionados a este trabalho são apresentados, fornecendo subsídios para o desenvolvimento do projeto de detecção de pessoas em ambiente fechado, usando mapas de profundidade. A subseção \ref{sec:biometria} expõe informações referentes à biometria e sistemas biométricos. A subseção \ref{sec:deteccao-rastreamento} apresenta conceitos relacionados à detecção e rastreamento de pessoas. A subseção \ref{sec:tec-rastreamento} discute o tópico tecnologias de rastreamento. Na subseção \ref{sec:determ-posic} são abordadas as técnicas de determinação de posição comumente utilizadas. A subseção \ref{sec:recFacial} explicita a definição de reconhecimento facial. Por fim, na subseção \ref{sec:kinect} são apresentadas informaçoes e conceitos referentes ao \textit{Microsoft Kinect}.

\subsection{Biometria e Sistemas Biométricos}\label{sec:biometria}
O termo biometria deriva do grego bios (vida) + metron (medida) e, na autenticação, refere-se à utilização de características próprias de um indivíduo para proceder à sua autenticação e/ou identificação \cite{magalhaes2003biometria}. Na biometria utiliza-se caracteristicas fisicas/fisiológicas ou comportamentais para a identificação de pessoas, sendo baseada em algo que a pessoa e e não em algo que ela possui ou sabe. A Figura~\ref{fig:biometria} ilustra exemplos de características biométricas \cite{cardia2015avaliaccao}.

\begin{figure*}[ht]
\centering
    \includegraphics[resolution=300,width=0.7\textwidth,natwidth=610,natheight=642]{images/biometria.png}
    \caption{Exemplos de características biométricas: impressão digital, orelha, termograma facial, termograma da mão, padrões de veias da mão, íris, retina, face e assinatura.}
    \label{fig:biometria}
\end{figure*}

Características fisicas/fisiológicas são baseadas na anatomia ou no funcionamento do organismo de uma pessoa viva, como impressão digitalou termograma facial. Já as comportamentais são baseadas na forma particular que um sujeito executa uma ação, como o a dinâmica de digitação ou a assinatura captada de modo digital. Qualquer característica pode ser utilizada desde que atenda algumas restrições, tais como \cite{maltoni2009handbook}:

\begin{itemize}
\item Universalidade: A característica deve estar presente na maior quantidade possível de pessoas;
\item Unicidade: A característica deve ser diferente entre pessoas diferentes;
\item Permanência: A característica não deve mudar com o passar do tempo;
\item Mensurabilidade: A característica deve ser fácil de coletar e mensurar;
\item Desempenho: A característica deve permitir alta acurácia com baixo tempo de processamento e custo computacional, além de ser robusta a ambientes não controlados;
\item Aceitabilidade: A característica deve ser aceita facilmente pelas pessoas como forma de identificação;
\item Grau de impostura: A característica deve ser resistente a fraude.
\end{itemize}

Um sistema de reconhecimento de padrões que utiliza um vetor de característica baseado em qualquer traço biométrico para garantir a identidade de uma pessoa é um sistema biométrico. Esses sistemas recebem a característica da pessoa, e processa em uma forma reduzida chamada de \textit{template}. Esse \textit{template} pode ser armazenado em um banco de dados central ou em um dispositivo de mídia removível.Segundo Wayman \cite{wayman2002}, um sistema biométrico pode ser classificado em uma das setes categorias: 

\begin{itemize}
\item Cooperativo ou não cooperativo: O sujeito deseja ser identificado?
\item Evidente ou sigiloso: O sujeito sabe que ele está sendo identificado?
\item Habituado ou não habituado: O sujeito frequentemente se submete a identificação?
\item Auxiliado ou não auxiliado: Existe um operador humano auxiliando o sistema?
\item Ambiente controlado ou não controlado: Em qual ambiente o sistema irá operar?
\item Privado ou público: Os sujeitos são empregados (privado) ou clientes (público)?
\item Aberto ou fechado: O sistema precisa de padrões para ter interoperabilidade entre sistemas?
\end{itemize}




\subsection{Detecção, identificação e rastreamento}\label{sec:deteccao-rastreamento}

As aplicações de localização interior têm experimentado esforços adicionais nos últimos anos com o aparecimento da computação ubíqua. Em vários cenários, objetos e mercadorias devem estar localizados ou monitorados, por exemplo, em um ambiente industrial ou médico. Adicionalmente, a localização de pessoas permite a criação de uma série de aplicativos e serviços. Clientes e funcionários podem ser observados, invasores detectados, idosos assistidos, e pacientes acompanhados. Em locais públicos, como estações de metrô, as preocupações de segurança podem ser abordadas por um sistema de orientação de emergência \cite{linde2006aspects}. 

Segundo Jaeseok Yun e Sang-Shin Lee \cite{yun2014human}, um sistema de controle de movimentos deve detectar robustamente: 
\begin{itemize}
  \item A identidade do objeto em movimento;
  \item Em qual o local está o objeto; 
  \item Em que sentido o objeto está se movimentando;
  \item O quão rápido esse objeto se move. 
 \end{itemize}

Uma das questões-chave da emergente computação móvel e robótica é a obtenção do conhecimento da posição de pessoas e objetos em um ambiente interno \cite{linde2006aspects}. A fim de construir um ambiente inteligente, onde os sistemas possam entender as atividades nas quais o usuário está envolvido e suas imediações, para então adaptar os seus serviços e recursos para o contexto do usuário, é necessário desenvolver um sistema de detecção, identificação e rastreamento de movimento robusto usando vários sensores \cite{yun2014human}. Esses três conceitos serão discutidos a seguir.


\subsubsection{Detecção de pessoas}\label{sec:deteccao-movimento}
Detectar seres humanos em imagens é uma tarefa desafiadora devido à sua aparência variável e à ampla gama de poses que eles podem adotar. A primeira necessidade é um conjunto de características robustas que permite que a forma humana seja discriminada de forma limpa, mesmo em ambientes despropositados sob iluminação difícil. Estudada a questão dos conjuntos de recursos para a detecção humana, dentre os principais métodos está  os descritores de histograma de desdobramento orientado (HOG) \cite{dalal2005histograms}. Os recursos baseados em gradientes, como HOG e EOH, envolvem a extração de pontos de interesse na imagem, como transformação de característica invariante em escala (EIPD), etc. Embora muitos relatórios mostrem que esses métodos Pode fornecer resultados de detecção de humanos altamente precisos, os métodos baseados em imagem RGB encontram dificuldades em perceber as formas dos seres humanos com poses articuladas ou quando o fundo é confuso. Isso resultará na diminuição da precisão ou no aumento do custo computacional\cite{dalal2005histograms}.

\subsubsection{Identificação de indivíduos}\label{sec:identificacao-pessoas}

Sistemas de sensores para identificação recolhem um conjunto de dados brutos do corpo humano, bem como extraem características distintas visando reconhecer o contexto principal: a identidade do objeto \cite{yun2014human}. Para esse fim, inúmeros sistemas têm sido estudados usando vários sensores, incluindo câmeras, sensores de movimento, blocos de pressão, radares, sensores de campo elétrico, etc.

O termo identificação significa o ato ou processo de estabelecer a identidade, ou reconhecer, ou ainda tratar uma coisa como idêntica a outra. Significa ainda o ato, ou processo, de fazer, representar ser, ou considerar ou tratar como o mesmo ou idêntico\cite{yun2014human} .

\subsubsection{Rastreamento de pessoas}\label{sec:rastre-amb-fec}

O acompanhamento do movimento das pessoas está se tornando importante em várias áreas de aplicação, onde a atividade dos indivíduos precisam ser analisadas ou monitoradas. Em tais aplicações, uma grande quantidade de informações pode ser obtida a partir de trajetórias que dão as coordenadas espaço-temporais de cada indivíduo no meio ambiente. As informações que podem ser obtidas a partir de tais trajetórias e incluem uma contagem dinâmica do número de pessoas dentro de uma área monitorada, o tempo gasto por indivíduos em uma área e padrões de fluxo de tráfego em um ambiente \cite{segen1996camera}. 

\subsection{Tecnologias de detecção Visuais, não visuais e combinadas}\label{sec:tec-rastreamento}
No geral, sistemas de monitoramento podem ser não visuais, visuais (com ou sem a utilização de marcadores) ou uma combinação de ambos \cite{zhou2008human}.

\subsubsection{Tecnologias visuais}\label{sec:sens-genericos}
Muitos pesquisadores têm dedicado os seus esforços para a construção de sistemas de detecção de movimento robustos usando sensores baseados na visão usando câmeras. Os projetos de investigação que utilizam sensores baseados em visão consideram, principalmente, posição, velocidade, direção, forma e tamanho (ou seja, o número de \textit{pixels} em câmeras) como o contexto principal para identificar os usuários e compreender as suas atividades \cite{stauffer200l}.

Existem duas principais técnicas no acompanhamento visual do movimento humano: rastreamento baseado marcador e rastreamento livre de marcador \cite{YTao2010}.

Rastreamento visual com marcador base (\textit{Visual marker based tracking}) é uma técnica onde as câmeras são utilizadas para controlar os movimentos humanos. São adicionados identificadores sobre o corpo humano. Devido ao fato de o esqueleto humano ser uma estrutura altamente articulada, torções e rotações podem gerar movimento muito complexos. Como consequência, cada parte do corpo realiza uma trajetória de movimento imprevisível e complicada, o que pode levar a estimativa de movimento inconsistente e pouco confiável. Além disso, cenas desordenadas, ou variação de iluminação podem distrair a atenção visual a partir da posição real de um marcador. Como uma solução para esses problemas, o rastreamento visual com marcador base é preferível nestas circunstâncias \cite{zhang2002visual}.

Sistemas de rastreamento baseado em marcador visual, são bastante utilizados como um "padrão" na análise de movimento humano devido à sua informação de posição precisa (os erros são de cerca de 1mm) \cite{zhang2002visual}. Esta função de precisão otimistamente motiva aplicações populares dos sistemas de rastreamento de marcadores visuais em medicina. Por exemplo, um Sistema de Captura de Movimento foi utilizado em um estudo para avaliar a relação entre os movimentos de equilíbrio corporal e as características antropométricas dos indivíduos, enquanto eles estavam em duas pernas com os olhos abertos e fechados \cite{kejonen2003}.

Entretanto, essas tecnologias possuem limitações as quais podem apresentar falhas devido:

\begin{enumerate}
    \item A identificação dos pontos ósseos padrões pode não ser confiável; 
    \item O tecido macio que se sobrepõe pontos ósseos podem mover-se, dando origem a dados ruidosos; 
    \item O próprio marcador pode oscilar devido à sua própria inércia; 
    \item Marcadores podem mesmo vir à deriva completamente.
\end{enumerate}

Sistemas visuais de rastreamento livres de marcador (\textit{Marker-free visual based tracking systems}) somente exploram sensores óticos para medir o movimentos do corpo humano. Esta aplicação é motivada pelas falhas do uso de sistemas baseados em marcador visual, anteriormente apresentadas. Como uma técnica de captura de movimento menos restritiva, os sistemas sem marcador são capazes de superar o problema de oclusão mútua, por exemplo, uma vez que se preocupam principalmente com os limites ou características dos corpos humanos\cite{zhou2008human}.

Câmeras mais avançadas podem fornecer uma resolução de um milhão de pixels, indicando uma alta precisão na detecção de movimentos de objetos. Além disso, as câmeras hoje em dia podem ser facilmente obtidas com um baixo custo, e os parâmetros podem ser configurados de forma flexível pelo usuário. Esses méritos incentivam as filmadoras a serem usadas popularmente em aplicações de vigilância. O \textit{trade-off} se dá pelo fato de que esta técnica requer uma computação intensiva para realizar a localização 3D e a redução de erros, além da minimização da latência dos dados \cite{bryson1993}. Além disso, são necessárias câmeras de alta velocidade, já que as câmeras convencionais (com uma taxa de amostragem inferior a sessenta quadros por segundo) fornecem uma largura de banda insuficiente para uma representação de dados precisa \cite{bhatnagar1993position}.


\subsubsection{Tecnologias não visuais}\label{sec:tec-vis}
Sensores utilizados nestes sistemas interagem direta ou indiretamente com o corpo humano a fim de recolher informações relativas ao movimento. Estes sensores são comumente classificados como mecânicos, inerciais, envoltório acústico, rádio ou micro-ondas e com base magnética \cite{zhou2008human}. De um modo geral, cada tipo de sensor tem as suas próprias vantagens e limitações. Limitações de modalidade específica, medição específica, e circunstâncias específicas afetam, consequentemente, o uso de tipos particulares de sensores, em ambientes diferentes \cite{Welch:2002}.

Mesmo que cada sensor tenha suas próprias desvantagens, outros sensores disponíveis podem ser usados como complemento. Por exemplo, para melhorar a precisão da computação de localização, as pessoas exploraram odômetros, em vez de acelerômetros, no projeto de robôs móveis \cite{zhou2008human}.

\subsubsection{Tecnologias combinadas de rastreamento}\label{sec:rastre-robo}
Estes sistemas tiram proveito das vantagens das tecnologias visuais e não visuais. Essa estratégia de combinação ajuda a reduzir erros decorrentes da utilização de plataformas individuais. Por exemplo, os limites ou silhuetas de partes do corpo humano podem ser capturados em uma trajetória de movimento, se marcadores montados sobre essas partes não estão no "campo de visão" das câmeras \cite{zhou2008human}.

Alguns dos componentes mais importantes desses sistemas são: a aquisição, processamento e interpretação da informação sensorial disponível. No nível mais baixo, a informação de detecção é utilizada para derivar sinais de controle, e a uma informação de nível mais elevado, são utilizados para criar modelos do sistema e do ambiente. A informação sensorial pode ser obtida através de uma variedade de sensores tais como: posição, velocidade, força, tátil, e a visão para citar alguns. Combinando elementos visuais e controladores pode resultar em um melhor algoritmo de rastreamento, mais eficazes e mais precisos, entretanto, essa estratégia exige alto poder de calibração e computação extremamente intensiva \cite{papanikolopoulos1993visual}.

\subsection{Técnicas de determinação de posição}\label{sec:determ-posic}
Por natureza, o posicionamento é um problema interdisciplinar que traz consigo inúmeras questões em vários campos de pesquisa, como engenharia, ciência da computação e estatística. Como consequência, a concepção e implementação de um sistema de localização é uma tarefa bastante complexa que implica um entendimento nesses domínios. No entanto, a metodologia de estimativa de localização é, em princípio, a mesma que utilizada nos tempos antigos, onde as pessoas usavam a constelação de estrelas para deduzir a localização. Hoje são utilizados dispositivos de referência fixos em locais conhecidos do nosso entorno. Então, o alvo móvel cuja posição deve ser determinada mede ângulos ou distâncias em direção a esses pontos de referência. \cite{linde2006aspects}. Algumas aplicações de localização interna encontram-se resumidas na tabela \ref{table:aplicacoes}.

\begin{table*}[ht]
\centering
\caption{Exemplos de aplicações que utilizam localização interna \cite{linde2006aspects}.}
\label{table:aplicacoes}
\begin{tabular}[ht]{llllllllp{2.5cm}p{8cm}}
\begin{sideways}Indústria \end{sideways} & \begin{sideways}Logística\end{sideways} & \begin{sideways}Comercial\end{sideways} & \begin{sideways}Médico\end{sideways} & \begin{sideways}Casas Inteligentes\end{sideways} & \begin{sideways}Lugares Públicos \end{sideways}& \begin{sideways}Turismo\end{sideways} & \begin{sideways}Redes de sensores\end{sideways} & Objetivo   & Propósito \\  \hline
$\boxtimes$ & $\boxtimes$ & $\Box$      & $\Box$      & $\Box$      & $\Box$      & $\Box$      & $\Box$      & Veículos guiados e robôs   & Navegação na unidade de produção ou armazém \\
$\boxtimes$ & $\boxtimes$ & $\boxtimes$ & $\boxtimes$ & $\boxtimes$ & $\Box$      & $\Box$      & $\Box$      & produtos   & Encontrar bens / objetos           \\
$\Box$      & $\Box$      & $\boxtimes$ & $\Box$      & $\Box$      & $\Box$      & $\Box$      & $\Box$      & Clientes   & Perfis dos hábitos dos clientes, assistente de compras pela navegação          \\
$\Box$      & $\Box$      & $\Box$      & $\Box$      & $\boxtimes$ & $\Box$      & $\Box$      & $\Box$      & Pessoas    & Controle climático da casa inteligente, características de conveniência, detecção de intruso, monitoramento eletrônico de prisão domiciliar          \\
$\Box$      & $\Box$      & $\Box$      & $\boxtimes$ & $\Box$      & $\Box$      & $\Box$      & $\Box$      & Pacientes  & Encontrar pacientes         \\
$\boxtimes$ & $\Box$      & $\boxtimes$ & $\boxtimes$ & $\Box$      & $\Box$      & $\Box$      & $\Box$      & Empregados & Observação e perfil          \\
$\Box$      & $\Box$      & $\Box$      & $\Box$      & $\Box$      & $\boxtimes$ & $\boxtimes$ & $\Box$      & Pessoas    & Sistemas de orientação de emergência          \\
$\Box$      & $\Box$      & $\Box$      & $\Box$      & $\Box$      & $\Box$      & $\Box$      & $\boxtimes$ & Nós        & Roteamento com localização, detecção distribuída \\ 
\hline         
\end{tabular}
\end{table*}

\subsubsection{Posição física e localização simbólica}\label{sec:posic-fisica}
A localização simbólica, ou posicionamento relativo, descreve o procedimento de determinação da posição atual de um alvo móvel usando o curso e a velocidade da informação. Pode ser subdividida em duas abordagens: odometria e navegação inercial \cite{linde2006aspects}.

Odometria é uma abordagem avançada para estimar navegação. Começando a partir de uma posição conhecida, a presente localização de uma unidade pode então ser determinada por meio da reconstrução do caminho percorrido. A odometria é totalmente autossuficiente mas, por outro lado, está sujeita a erros. Esses erros podem ser sistemáticos, como por exemplo erros causados por diâmetros desiguais ou desalinhamento das rodas, ou não sistemáticos, como por exemplo movimento sobre solos não uniformes ou sobre obstáculos inesperados. 

Sistemas de navegação inercial (INS) usam giroscópios e acelerômetros para medir a velocidade de rotação e aceleração de uma unidade. A Informação sobre a posição é calculada mediante a integração dos dados medidos duas vezes. Assim como os sistemas de odometria, os sistemas de navegação inercial são autossuficientes, mas estão susceptíveis aos mesmos erros que podem ocorrer em sistemas de odometria. Um sistema inercial pode ajudar a compensar erros de odometria momentâneas \cite{linde2006aspects}.

A posição física, ou absoluta, de uma unidade móvel pode ser determinada com a ajuda de pontos de referência fixos localizados no ambiente. A posição destes pontos de referência é conhecida a priori e essas referências podem ser componentes ativos ou passivos. Esta técnica apresenta três abordagens: registro de balizas, ponto de referência e modelo de harmonização \cite{linde2006aspects}.

Balizas ativas são componentes estáticos localizados em posições fixas e conhecidas do ambiente. Existem dois tipos diferentes de balizas: balizas auto atuantes que emitem periodicamente certa assinatura (por exemplo, uma sequência de \textit{bits} única), e balizas sensíveis. Balizas sensíveis podem atuar como ouvintes ou ativamente refletir uma assinatura recebida emitida pela unidade móvel. Ponto de referência são características estáticas de um ambiente que podem ser reconhecidos por uma unidade móvel. Na maioria das vezes, esses marcos são formas geométricas, como retângulos, linhas ou códigos de barras. Além desses objetos artificiais, itens naturais, como portas também podem servir como pontos de referência. Além disso, a análise geral da cena é frequentemente utilizada neste contexto. No modelo de harmonização, uma unidade móvel deve ser capaz de construir um mapa ou modelo de um ambiente desconhecido e, ao mesmo tempo localizar-se no interior deste mapa. Enquanto se move e explora, um modelo de referência é criado. O posicionamento é realizado comparando este modelo de referência (possivelmente pré-armazenado) a um modelo local gerado a partir dos dados dos sensores a bordo \cite{linde2006aspects}.

\subsubsection{Trilateração}\label{sec:trilat}
A trilateração é uma técnica para calcular uma posição de um objeto $m$, tendo suas distâncias $l_{am}$, $l_{bm}$ e $l_{cm}$ para três objetos de referência não colineares\footnote{ Cálculo para um cenário 2D. A localização em 3D requer quatro referências não coplanares} fixos $a, b$ e $c$ (ver Fig.~\ref{fig:trilateracao}). Para cada distância $l_{pm}$ entre $m$ e $p$ (com $p \in \{a, b, c\}$), um círculo em ($x_{p}, y_{p}$) com raio $l_{pm}$ pode ser desenhado em torno de $p$. O ponto de interseção de três desses círculos produz as coordenadas ($x_{m}, y_{m}$) de $m$. Portanto, a trilateração pode ser expressa como encontrar a solução para o seguinte sistema de equações quadráticas \cite{linde2006aspects}:

\begin{align*}
(x_{m}-x_{a})^{2} + (y_{m}-y_{a})^{2} = {l_{am}}^{2}\\
(x_{m}-x_{b})^{2} + (y_{m}-y_{b})^{2} = {l_{bm}}^{2}\\
(x_{m}-x_{c})^{2} + (y_{m}-y_{c})^{2} = {l_{cm}}^{2}
\end{align*}



 \begin{figure}[h]
\centering
    \includegraphics[resolution=300,width=0.39\textwidth,natwidth=610,natheight=642]{images/trilateracao.png}
    \caption{Esquema de Trilateração.}
    \label{fig:trilateracao}
\end{figure}


\begin{figure*}[ht]
\centering
\includegraphics[resolution=300,width=0.7\textwidth,natwidth=610,natheight=642]{images/triangulacao.png}
    \caption{Esquemas de triangulação.}
    \label{fig:triang}
\end{figure*}

\subsubsection{Triangulação}\label{sec:triang}


A localização baseada na trilateração implica que os participantes devem ser capazes de medir distâncias (ou diferenças de distância) entre si. A triangulação funciona de forma semelhante, mas em vez de distâncias, os ângulos são medidos. De fato, pode-se demonstrar que a triangulação pode ser transformada em trilateração por meios simples\cite{linde2006aspects}. 

Triangulação requer a medição de ângulos entre as unidades de referência fixas e o alvo móvel. As unidades móveis calculam os ângulos em direção aos sinais emitidos por unidades fixas de referência. Obtém-se então a posição e orientação através dos dados recolhidos. As unidades de referência medem os ângulos na direção do sinal emitido pela unidade móvel. Apenas uma estimativa da localização, mas não a orientação do alvo móvel, pode ser obtida \cite{lutzke2013experimental}. Dois casos podem ser distinguidos, conforme ilustrado na Fig.~\ref{fig:triang}:


\begin{itemize}
  \item A unidade móvel mede os ângulos em direção a sinais emitidos por unidades de referência fixas (ver Fig.~\ref{fig:triang}(a)). Os dados recolhidos fornecem a posição e orientação.
  \item As unidades de referência medem ângulos em direção ao sinal emitido pela unidade móvel (ver Fig.~\ref{fig:triang}(b)). Apenas uma estimativa de localização, mas não a orientação do alvo móvel, pode ser obtida.
 \end{itemize}


\subsubsection{Proximidade e análise de cena}\label{sec:proximidade}
Outra abordagem de localização é a técnica de detecção de proximidade na qual a posição de um alvo é aproximada, selecionando a localização da unidade de referência mais próxima. Por conseguinte, não é necessário cálculo de localização. Alternativamente, se várias unidades de referência estão dentro do alcance, o baricentro entre estas unidades podem produzir uma melhor estimativa \cite{EHuber1996}.

Pontos de referência (\textit{Landmarks}) são elementos estáticos de um ambiente que pode ser reconhecido por uma unidade móvel. Na maioria das vezes, os pontos de referência são formas geométricas, como retângulos, linhas ou códigos de barras. Itens naturais, como portas podem também servir como pontos de referência. O termo  análise de cena é frequentemente utilizado neste contexto. Unidades móveis tentam localizar-se  em determinado ambiente usando a visão da câmera, bem como funcionalidades de extração para analisar o cenário atual. Uma vez que um marco foi reconhecido e identificado de forma confiável, a posição atual da unidade em relação ao marco correspondente pode ser calculada. Isto é conseguido através de triangulação, trilateração e proximidade \cite{linde2006aspects}.


 \subsection{Reconhecimento facial}\label{sec:recFacial}
O reconhecimento facial é uma forma de identificar pessoas. Em desenvolvimento há muitos anos. esses sistemas permitem identificar alguém a um longo alcance, porém limitado principalmente pela resolução da câmera utilizada. No entanto, esta solução vem com algumas desvantagens. A adição de vigilância para o vídeo é necessária e, mesmo que seja explicitamente afirmado que as imagens são processadas e não armazenadas, ainda suscita preocupações que podem causar desconforto a alguns usuários. Outra desvantagem é que o software de reconhecimento facial não é muito confiável quando se trata de identificar dois seres semelhantes, como irmãos gêmeos idênticos \cite{fitzpatrick2013real}.

O reconhecimento de faces e mais vantajoso nesse aspecto, pois é possível realizar a identificação de uma pessoa sem ela cooperar ou saber que está sendo identificado. Primeiro é necessário detectar e segmentar faces de cenas complexas (Detecção de Faces). Para cada face, o processo de extração de característica é aplicado (Extração de Característica) e as caracteristicas extraídas são comparadas com os templates cadastrados na galeria de faces. A decisão sobre a identidade da face é então tomada (Reconhecimento de face) \cite{cardia2015avaliaccao}.   
 
 \subsection{Kinect}\label{sec:kinect}
 
O Kinect (Fig.~\ref{fig:kinect}) é um sensor de movimento, projetado pela Microsoft Inc. e lançado em novembro de 2010 para ser usado como controle remoto para o console de videogames Xbox 360. É composto por vários sensores (Fig. ~\ref{fig:kinect}): Uma câmera RGB (Color CMOS, VNA38209015), uma câmera de profundidade composta por um projetor de infravermelho(\textit{infrared} - IR) (OG12 / 0956 / D306 / JG05A) combinado a uma câmera de infravermelho (IR CMOS, Microsoft / X853750001 / VCA379C7130) e uma série de quatro microfones. A câmera infravermelha e a câmera colorida têm uma definição de 640 x 480 pixels. O ângulo de visão é $60\,^{\circ}$ horizontal e $45\,^{\circ}$ vertical. O dispositivo foi projetado para ser usado em uma faixa de 0,5 m a 5 m \cite{sevrin2015characterization}. A tabela \ref{table:comparativoScanners} apresenta um comparativo entre o Kinect e os \textit{scanners} 3D mais utilidados.

 \begin{figure}[h]
\centering
    \includegraphics[resolution=300,width=0.4\textwidth,natwidth=610,natheight=642]{images/kinect.png}
    \caption{O Sensor Microsoft Kinect.}
    \label{fig:kinect}
\end{figure}


 \begin{table}[h]
 \caption{Comparação entre diferentes \textit{scanners} 3D \cite{li2013using}.\newline A velocidade é expressada em segundos, tamanho em polegadas, preço em USD e a acurácia é uma aproximação expressada em mm.}
 \label{table:comparativoScanners}
 \begin{tabular}{|l|c|c|c|c|c|}
\hline  
 Dispositivo & Velocidade & Carga & tamanho & Preço & Acurácia \\ \hline  
 3dmD & 0.002 & 10 s & N/A & >\$50k & <0.2 \\ \hline  
 Minolta & 2.5 & Não & 1408 & >\$50k & 0.1 \\ \hline  
 Artec Eva & 0.063 & Não & 160.8 & >\$20k & 0.5 \\ \hline  
 3D3 HDI R1 & 1.3 & Não & N/A & >\$10k & 0.3 \\ \hline  
 SwissRanger & 0.02 & Não & 17.53 & >\$5k & 10 \\ \hline  
 David SLS & 2.4 & Não & N/A & >\$2k & 0.5 \\ \hline  
 Kinect & 0.033 & Não & 41.25 & >\$200k & 1.5-50 \\ \hline
\end{tabular}
\end{table}


 \subsubsection{Câmera de profundidade (\textit{Depth-camera})}\label{sec:depth}
A câmera de profundidade é um dispositivo que pode detectar diretamente o alcance da superfície física mais próxima em cada pixel. A câmera de profundidade é única porque possibilita a modelagem 3D em tempo real da geometria da superfície. As câmeras de profundidade oferecem várias vantagens em relação aos sensores de intensidade tradicionais, trabalhando em baixos níveis de luz, fornecendo uma estimativa de escala calibrada, sendo invariante de cores e texturas e resolvendo ambiguidades de silhueta em pose. Eles também simplificam muito alguns difíceis problemas de visão computaconal, como a remoção de fundo falso em uma aplicação de videoconferência \cite{wilson2010combining}. Além disso, é capaz de sintetizar imagens de profundidade realistas de pessoas e, assim, criar um grande conjunto de dados de treinamento, com baixo custo. Algumas das tecnologias usadas para obter informações de profundidade da câmera em profundidade são luz infravermelha e estruturada de tempo de vôo (\textit{time-of-flight}) \cite{bogomjakov2006free}.


\subsubsection{Nuvem de pontos (\textit{Depth-camera})}\label{sec:nuvem}
A nuvem de pontos é uma estrutura de dados usada para representar uma coleção de pontos multi-dimensionais e é comumente usada para representar dados tridimensionais. Em uma nuvem de pontos 3D, os pontos geralmente representam as coordenadas geométricas $X$, $Y$ e $Z$ de uma superfície subjacente amostrada. Quando as informações de cor estão presentes, a nuvem torna-se ponto 4D \cite{gustavo2014Localizacao}.

\subsubsection{Triangulação estéreo }\label{sec:steroTriang}
Triangulação estéreo é um algoritmo de análise para calcular a posição 3D de pontos em um quadro de imagem. Em geral, triangulação estéreo, duas imagens são usadas para obter as duas visualizações diferentes em uma cena, de forma semelhante à visão binocular humana. Ao comparar essas duas imagens, a informação de profundidade relativa é calculada \cite{kinect4Windows}. 

Este trabalho, utiliza uma recente abordagem sensorial: a utilização de mapas de profundidade para a detecção de presença em um ambiente interno. Tratando-se de um sistema biométrico, do tipo físico, tendo como características desse tipo de sistema: não cooperativa, sigilosa, não habituado, não auxiliado e \textit{less intrusive}. A partir de tecnologias visuais, livre de marcador, o SDK utiliza processos de triangulação estéreo para extração do mapa de profundidade, calculando a partir desse, a posição física dos indivíduos.

\subsubsection{Inferência de partes do corpo e sugestão de \textit{joints}}\label{sec:bodyProposal}

Uma contribuição fundamental do trabalho realizado pela \textit{Microsoft} \cite{Shotton:2013:RHP:2398356.2398381} no desenvolvimento do \textit{Kinect} SDK é a representação parcial de partes do corpo. São Definidos vários rótulos de partes localizadas de um individuo, que cobrem densamente o corpo, como codificado por cores na Figura \ref{fig:bodyparts}. Algumas dessas partes são definidas para localizar diretamente as articulações esqueléticas de interesse, enquanto outras preenchem as lacunas ou podem ser usadas em combinação para prever outras articulações.

As partes são especificadas em um mapa de textura que é retornado para diminuir os vários caracteres durante a renderização. Os pares de imagem e profundidade da parte do corpo são usados como dados totalmente rotulados
para o aprendizado do algoritmo classificador. Para os experimentos foram usadas 31 partes do corpo (E-Esquerda, D-Direita, S-Superior, I-Inferior): cabeça (ES, DS, EI, DI), pescoço, ombro (E, D), braço (ES, DS, EI, DI),cotovelo (E, D), pulso (E, D), mão (E, D), torso (ES, DS, EI, DI), perna (ES, DS, EI, DI), joelho (E, D), tornozelo (E, D) e pé (E, D). Partes distintas para esquerda e direita permitem ao classificador desambiguar os lados esquerdo e direito do corpo \cite{Shotton:2013:RHP:2398356.2398381}.

\begin{figure*}[ht]
\centering
\includegraphics[resolution=300,width=1.0\textwidth,natwidth=610,natheight=642]{images/body_parts.png}
    \caption{Dados sintéticos e reais. Pares de imagens de produndidade e partes verdadeiras do corpo, com grande variedade de pose, forma, roupa e cortes \cite{Shotton:2013:RHP:2398356.2398381}.}
    \label{fig:bodyparts}
\end{figure*}

\paragraph{Florestas de decisão aleatória }\label{sec:forests}
As árvores e florestas de decisão aleatória [35, 30, 2, 8] demonstraram classificações rápidas e eficazes para várias tarefas [20, 23, 36], e podem ser implementadas de forma eficiente na GPU [34]. Conforme ilustrado na Fig. 4, uma floresta é um conjunto de árvores de decisão $T$, cada uma constituída por nós de divisão e folhas. Cada nó dividido consiste em uma característica ${f_{\theta}}$ e um limite $\tau$. Para classificar o pixel $x$ na imagem $I$, um começa na raiz e avalia repetidamente a equação \ref{eq:eq1} \textcolor{red}{MOVER EQUACAO 1 DA PARTE PRATICA PARA O REFERENCIAL TEORICO}, ramificando para a esquerda ou para a direita de acordo com a comparação com o limite $\tau$. No nó da folha alcançado na árvore $t$, uma distribuição aprendida $P_{t} (c | I, x)$ sobre as etiquetas das partes do corpo $c$ é armazenada. As distribuições são calculadas em média para todas as árvores na floresta para dar a classificação final.

\begin{align}
P(c | I, x) = \frac{1}{T} \sum_{t=1}^{T} P_{t} (c | I, x).
\label{eq:eq2}
\end{align}

\textcolor{red}{PAREI NA FORMULA ACIMA, NA REFERENCIA ABAIXO (COMENTADA)}
%https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/BodyPartRecognition.pdf